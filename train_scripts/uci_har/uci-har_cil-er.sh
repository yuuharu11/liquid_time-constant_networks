#!/bin/bash
set -e

# --- å®Ÿé¨“è¨­å®š (ç·¨é›†ç®‡æ‰€) ---
EXPERIMENT_CONFIG="ltc_ncps/uci_har" # Hydraã®å®Ÿé¨“è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
RESULTS_DIR="/work/outputs/ltc_ncps/cil/er_sweep" # çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
WANDB_PROJECT="UCI-HAR-CIL-ER-Sweep" # Weights & Biases ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
SEED=42
NUM_TASKS=5 # CILã‚¿ã‚¹ã‚¯ã®ç·æ•°
EPOCHS=30

# --- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚¹ã‚¤ãƒ¼ãƒ—è¨­å®š ---
MEMORY_SIZES=(100 250)
REPLAY_BATCH_SIZES=(32 64 96)

echo "ğŸš€ Starting CIL with Experience Replay sweep for UCI-HAR..."
echo "=================================================================="

# --- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ«ãƒ¼ãƒ— ---
for mem_size in "${MEMORY_SIZES[@]}"; do
  for replay_bs in "${REPLAY_BATCH_SIZES[@]}"; do

    SWEEP_NAME="mem${mem_size}_bs${replay_bs}"
    echo ""
    echo "--- Running Sweep: ${SWEEP_NAME} ---"

    # --- ã‚¹ã‚¤ãƒ¼ãƒ—ã”ã¨ã®åˆæœŸåŒ– ---
    LAST_CHECKPOINT_PATH="" # æœ€åˆã®ã‚¿ã‚¹ã‚¯ã§ã¯ pretrained_model_path ã‚’ä½¿ã‚ãªã„
    BUFFER_PATH="/work/buffer/er_buffer_${SWEEP_NAME}.pt"
    CSV_LOG_PATH="/work/csv/uci-har/cil-er/${SWEEP_NAME}.csv"

    # ä»¥å‰ã®ãƒãƒƒãƒ•ã‚¡ãŒæ®‹ã£ã¦ã„ã‚Œã°å‰Šé™¤
    rm -f $BUFFER_PATH
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    mkdir -p "$(dirname "$CSV_LOG_PATH")"


    # --- CIL ã‚¿ã‚¹ã‚¯ãƒ«ãƒ¼ãƒ— (0ã‹ã‚‰NUM_TASKS-1ã¾ã§) ---
    for i in $(seq 0 $(($NUM_TASKS - 1))); do
      
      TASK_NAME="Task_${i}"
      OUTPUT_DIR="${RESULTS_DIR}/${SWEEP_NAME}/${TASK_NAME}"
      GROUP_NAME="${SWEEP_NAME}" # WandBã§ã®ã‚°ãƒ«ãƒ¼ãƒ—å

      echo "--- Training ${TASK_NAME} ---"

      # --- å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ã®çµ„ã¿ç«‹ã¦ ---
      CMD="python3 train.py \
          experiment=${EXPERIMENT_CONFIG} \
          dataset=uci_har_cil \
          train.seed=$SEED \
          dataset.seed=$SEED \
          dataset.task_id=$i \
          trainer.max_epochs=$EPOCHS \
          hydra.run.dir=$OUTPUT_DIR \
          wandb.project=$WANDB_PROJECT \
          wandb.group=$GROUP_NAME \
          wandb.name=\"${SWEEP_NAME}-${TASK_NAME}\" \
          callbacks.experiment_logger.output_file=$CSV_LOG_PATH \
          train.replay._name_=exact_replay \
          train.replay.memory_size=$mem_size \
          train.replay.batch_size=$replay_bs \
          train.replay.buffer_path=$BUFFER_PATH"

      # Task 0 ä»¥å¤–ã§ã¯ã€å‰ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€
      if [ -n "$LAST_CHECKPOINT_PATH" ]; then
        CMD="$CMD train.pretrained_model_path=$LAST_CHECKPOINT_PATH"
      fi
      
      # --- å­¦ç¿’ã®å®Ÿè¡Œ ---
      eval $CMD

      # --- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ‘ã‚¹ã‚’æ›´æ–° ---
      LAST_CHECKPOINT_PATH="${OUTPUT_DIR}/checkpoints/last.ckpt"
      
      # --- éå»ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€å…¨ã‚¿ã‚¹ã‚¯ã§ã®è©•ä¾¡ ---
      echo "--- Evaluating ${TASK_NAME} model on all learned tasks (0 to ${i}) ---"
      for j in $(seq 0 $i); do
        
        PAST_TASK_NAME="Task_${j}"
        EVAL_DIR="${OUTPUT_DIR}/eval_on_${PAST_TASK_NAME}"
        
        echo "---   Testing on ${PAST_TASK_NAME} ---"
        python3 train.py \
            experiment=${EXPERIMENT_CONFIG} \
            dataset=uci_har_cil \
            train.seed=$SEED \
            dataset.seed=$SEED \
            dataset.task_id=$j \
            hydra.run.dir=$EVAL_DIR \
            train.pretrained_model_path=$LAST_CHECKPOINT_PATH \
            train.test_only=true \
            callbacks.experiment_logger.output_file=$CSV_LOG_PATH
      done
      echo "--------------------------------------------------"

      echo "---  Training and evaluation Joint Training ---"
      python3 train.py \
          experiment=${EXPERIMENT_CONFIG} \
          dataset=uci_har_cil \
          train.seed=$SEED \
          trainer.max_epochs=$EPOCHS \
          dataset.seed=$SEED \
          dataset.task_id=$i \
          train.test=true \
          callbacks.experiment_logger.output_file=$CSV_LOG_PATH

    done
    echo "Sweep ${SWEEP_NAME} finished."
    echo "=================================================================="
  done
done

echo "âœ… All CIL experiments finished."
echo "=================================================================="