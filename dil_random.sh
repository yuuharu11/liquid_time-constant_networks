#!/bin/bash
set -e

# --- å®Ÿé¨“ã®åŸºæœ¬è¨­å®š ---
BASE_EXPERIMENT="ltc_ncps/mnist"
WANDB_PROJECT="ncps_continual_learning"

# --- çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®Bashé…åˆ—ã‚’åˆæœŸåŒ– ---
declare -a results_on_own_task # è‡ªèº«ã®ã‚¿ã‚¹ã‚¯ã§ã®ç²¾åº¦
declare -a results_on_task0    # Task0ã§ã®ç²¾åº¦

task_0_OUTPUT_DIR="/work/outputs/ncps/DIL/random/train_task_0"

python3 train.py \
    experiment=$BASE_EXPERIMENT \
    dataset.seed=0 \
    dataset.permute=false \
    trainer.max_epochs=10 \
    hydra.run.dir=$task_0_OUTPUT_DIR \
    train.test=true \
    wandb.project=$WANDB_PROJECT \
    wandb.name="ncps_train_0" \
    callbacks.experiment_logger.output_file="/work/test/DIL.csv"

task_0_CHECKPOINT_PATH="${task_0_OUTPUT_DIR}/checkpoints/last.ckpt"

# ==================================================================
# --- ãƒ«ãƒ¼ãƒ—ã§Task 1ã‹ã‚‰9ã¾ã§ã€ãã‚Œãã‚Œãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ»è©•ä¾¡ ---
# ==================================================================
for i in {1..9}; do
  
  # --- 1. Task i ã§ã®è¨“ç·´ ---
  RUN_NAME="train_task_${i}"
  prev_task_num=$((i - 1))
  last_checkpoint="/work/outputs/ncps/DIL/random/train_task_${prev_task_num}/checkpoints/last.ckpt"
  OUTPUT_DIR="/work/outputs/ncps/DIL/random/train_task_${i}"

  echo ""
  echo "=================================================================="
  echo "--- 1. Training model on Task ${i} (seed=${i}) ---"
  echo "=================================================================="

  
  python3 train.py \
    experiment=$BASE_EXPERIMENT \
    dataset.permute=true \
    dataset.seed=$i \
    trainer.max_epochs=10 \
    train.pretrained_model_path=$last_checkpoint \
    hydra.run.dir=$OUTPUT_DIR \
    wandb.project=$WANDB_PROJECT \
    wandb.name="ncps_train_${RUN_NAME}" \
    train.test=true \
    callbacks.experiment_logger.output_file="/work/test/DIL.csv" \

  CHECKPOINT_PATH="${OUTPUT_DIR}/checkpoints/last.ckpt"
  echo "âœ… Training for Task ${i} complete. Checkpoint: ${CHECKPOINT_PATH}"

  # --- 3. Test on all previous tasks ---
  echo "--- Testing model on ALL previous tasks (0 to ${i}) ---"

  # Use seq to generate the sequence for the inner loop
  for j in $(seq 0 $i); do
      echo "---   Testing on Task ${j} ---"

      # Set the permute flag based on the task number (j)
      PERMUTE_FLAG_TEST=true
      if [ $j -eq 0 ]; then
          PERMUTE_FLAG_TEST=false
      fi

      python3 train.py \
          experiment=$BASE_EXPERIMENT \
          train.pretrained_model_path=${CHECKPOINT_PATH} \
          train.test_only=true \
          dataset.permute=$PERMUTE_FLAG_TEST \
          dataset.seed=$j \
          callbacks.experiment_logger.output_file="/work/test/DIL.csv" \

  done
done


# --- 4. å…¨ã¦ã®å®Ÿé¨“ãŒå®Œäº†ã—ãŸå¾Œã€çµæœã‚’ã¾ã¨ã‚ã¦å‡ºåŠ› ---
echo ""
echo "=================================================================="
echo "--- ğŸ“œ Final Transfer Learning Test Results ---"
echo "=================================================================="
echo "Trained on | Acc on Own Task | Acc on Task 0"
echo "------------------------------------------------"
echo "=================================================================="
echo "All experiments finished!"