import csv
import os
import time
import numpy as np
import torch
import pytorch_lightning as pl
from pytorch_lightning import Callback, Trainer
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
from rich import print

# --- Monitor Callbacks (å¤‰æ›´ã®å¿…è¦ãªã—) ---

class TrainingMonitor(Callback):
    """è¨“ç·´ä¸­ã®GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¨ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®å­¦ç¿’æ™‚é–“ã‚’è¨ˆæ¸¬ã™ã‚‹"""
    def on_train_epoch_start(self, trainer, pl_module):
        self.epoch_start_time = time.perf_counter()
        self.batch_peak_memory = []
        if pl_module.device.type == 'cuda':
            torch.cuda.reset_peak_memory_stats(pl_module.device)

    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        if pl_module.device.type == 'cuda':
            self.batch_peak_memory.append(torch.cuda.max_memory_allocated(pl_module.device))
            torch.cuda.reset_peak_memory_stats(pl_module.device)

    def on_train_epoch_end(self, trainer, pl_module):
        epoch_duration = time.perf_counter() - self.epoch_start_time
        pl_module.log("training/epoch_duration_sec", epoch_duration, on_step=False, on_epoch=True, logger=True)
        
        if self.batch_peak_memory and pl_module.device.type == 'cuda':
            avg_peak_memory_mb = np.mean(self.batch_peak_memory) / (1024**2)
            pl_module.log("training/avg_peak_mb", avg_peak_memory_mb, on_step=False, on_epoch=True, logger=True)
            print(f"\n[cyan]TrainingMonitor: Avg Peak Memory this Epoch: {avg_peak_memory_mb:.2f} MB, Duration: {epoch_duration:.2f} sec[/cyan]")

class InferenceMonitor(Callback):
    """ãƒ†ã‚¹ãƒˆï¼ˆæ¨è«–ï¼‰ä¸­ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨ˆæ¸¬ã™ã‚‹"""
    def on_test_epoch_start(self, trainer, pl_module):
        self.latencies = []
        self.peak_memory = []
        print("\n[yellow]InferenceMonitor: Starting measurement...[/yellow]")

    def on_test_batch_start(self, trainer, pl_module, batch, batch_idx, dataloader_idx):
        if pl_module.device.type == 'cuda':
            torch.cuda.synchronize()
            torch.cuda.reset_peak_memory_stats(pl_module.device)
        self.start_time = time.perf_counter()

    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):
        if pl_module.device.type == 'cuda':
            torch.cuda.synchronize()
            self.peak_memory.append(torch.cuda.max_memory_allocated(pl_module.device))
        
        latency = time.perf_counter() - self.start_time
        self.latencies.append(latency)

    def on_test_epoch_end(self, trainer, pl_module):
        if not self.latencies: return
        stable_latencies = self.latencies[1:] if len(self.latencies) > 1 else self.latencies
        avg_stable_latency_ms = np.mean(stable_latencies) * 1000
        p95_latency_ms = np.percentile(stable_latencies, 95) * 1000
        
        pl_module.log("inference/avg_latency_ms", avg_stable_latency_ms, logger=True)
        pl_module.log("inference/p95_latency_ms", p95_latency_ms, logger=True)

        avg_peak_memory_mb = 0.0
        if self.peak_memory and pl_module.device.type == 'cuda':
            avg_peak_memory_mb = np.mean(self.peak_memory) / (1024**2)
            pl_module.log("inference/avg_peak_mb", avg_peak_memory_mb, logger=True)
        
        print(f"[green]InferenceMonitor: Avg Latency: {avg_stable_latency_ms:.2f} ms/batch, Avg Memory: {avg_peak_memory_mb:.2f} MB[/green]")

# --- ä¸»å½¹ã¨ãªã‚‹CSVãƒ­ã‚¬ãƒ¼ (ã“ã“ã‚’ä¿®æ­£) ---

class CSVSummaryCallback(Callback):
    """è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®çµæœã‚’ã¾ã¨ã‚ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ã™ã‚‹"""
    def __init__(self, output_file="results/summary.csv"):
        super().__init__()
        self.output_file = output_file
        self.results_cache = {}
        self.has_written_this_run = False
        self.headers = [
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ãƒ¢ãƒ‡ãƒ«", "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", "dataset_seed", "LSTMCell", "optimizer", "scheduler",
            "batch", "model.n_layers", "model.d_model", "units", "output_units",
            "ã‚¨ãƒãƒƒã‚¯æ•°", "ode_solver_unfolds", "input_mapping",
            "æ¤œè¨¼ç²¾åº¦ (Val Acc)", "ãƒ†ã‚¹ãƒˆç²¾åº¦ (Test Acc)", "å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms/ãƒãƒƒãƒ)",
            "p95 ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms/ãƒãƒƒãƒ)", "å­¦ç¿’æ™‚é–“/epoch", "è¨“ç·´æ™‚ Memoey Allocated [MB]",
            "æ¨è«–æ™‚ Memoey Allocated [MB]", "ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹", "wandbãƒªãƒ³ã‚¯", "å‚™è€ƒ"
        ]

    def _get_metric(self, metrics_dict, key, default=-1.0):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®‰å…¨ã«å–å¾—ã—ã€ãƒ†ãƒ³ã‚½ãƒ«ãªã‚‰.item()ã‚’å‘¼ã¶è£œåŠ©é–¢æ•°"""
        value = metrics_dict.get(key, default)
        return value.item() if isinstance(value, torch.Tensor) else value

    def _capture_hparams(self, pl_module):
        """ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã™ã‚‹è£œåŠ©é–¢æ•°"""
        hparams = pl_module.hparams
        self.results_cache["ãƒ¢ãƒ‡ãƒ«"] = hparams.model._name_
        self.results_cache["ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"] = hparams.dataset._name_
        self.results_cache["dataset_seed"] = hparams.dataset.get("seed", "N/A")
        self.results_cache["LSTMCell"] = hparams.model.layer.get("mixed_memory", "N/A")
        self.results_cache["optimizer"] = "adamw"
        self.results_cache["scheduler"] = "cosine_warmup"
        self.results_cache["batch"] = hparams.loader.batch_size
        self.results_cache["model.n_layers"] = hparams.model.get("n_layers", "N/A")
        self.results_cache["model.d_model"] = hparams.model.get("d_model", "N/A")
        
        units_list = hparams.model.layer.get("units", [])
        self.results_cache["units"] = next((item.get("units") for item in units_list if "units" in item), "N/A")
        self.results_cache["output_units"] = next((item.get("output_units") for item in units_list if "output_units" in item), "N/A")
        self.results_cache["ode_solver_unfolds"] = hparams.model.layer.get("ode_unfolds", "N/A")
        self.results_cache["input_mapping"] = hparams.model.layer.get("input_mapping", "N/A")

    def on_train_end(self, trainer: Trainer, pl_module):
        """è¨“ç·´å®Œäº†æ™‚ã«å‘¼ã³å‡ºã•ã‚Œã€è¨“ç·´çµæœã‚’ä¸€æ™‚ä¿å­˜ã™ã‚‹"""
        self._capture_hparams(pl_module)
        metrics = trainer.logged_metrics

        self.results_cache["ã‚¨ãƒãƒƒã‚¯æ•°"] = trainer.current_epoch + 1
        val_metric_key = f"val/{pl_module.hparams.task.get('metric', 'accuracy')}"
        self.results_cache["æ¤œè¨¼ç²¾åº¦ (Val Acc)"] = self._get_metric(metrics, val_metric_key)
        self.results_cache["å­¦ç¿’æ™‚é–“/epoch"] = self._get_metric(metrics, "training/epoch_duration_sec")
        self.results_cache["è¨“ç·´æ™‚ Memoey Allocated [MB]"] = self._get_metric(metrics, "training/avg_peak_mb")
        
        print("\n[bold cyan]CSVSummaryCallback: è¨“ç·´çµæœã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¾ã—ãŸã€‚ãƒ†ã‚¹ãƒˆå®Œäº†å¾Œã«è¨˜éŒ²ã—ã¾ã™ã€‚[/bold cyan]")

    def on_test_start(self, trainer: Trainer, pl_module):
        """ãƒ†ã‚¹ãƒˆé–‹å§‹æ™‚ã«å‘¼ã³å‡ºã•ã‚Œã€æ›¸ãè¾¼ã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        self.has_written_this_run = False

    def on_test_end(self, trainer: Trainer, pl_module):
        """ãƒ†ã‚¹ãƒˆå®Œäº†æ™‚ã«å‘¼ã³å‡ºã•ã‚Œã€å…¨ã¦ã®æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ä¸€åº¦ã ã‘æ›¸ãè¾¼ã‚€"""
        if self.has_written_this_run:
            return  # 2å›ç›®ä»¥é™ã®å‘¼ã³å‡ºã—ã¯ç„¡è¦– (é‡è¤‡æ›¸ãè¾¼ã¿é˜²æ­¢)

        # test_onlyãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€è¨“ç·´æƒ…å ±ãŒãªã„ã®ã§ã€ã“ã“ã§hparamsã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹
        if not self.results_cache:
            self._capture_hparams(pl_module)
            self.results_cache["ã‚¨ãƒãƒƒã‚¯æ•°"] = trainer.max_epochs # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—

        metrics = trainer.callback_metrics

        # ãƒ†ã‚¹ãƒˆçµæœã‚’è¿½åŠ 
        test_metric_key = f"final/test/{pl_module.hparams.task.get('metric', 'accuracy')}"
        self.results_cache["ãƒ†ã‚¹ãƒˆç²¾åº¦ (Test Acc)"] = self._get_metric(metrics, test_metric_key)
        self.results_cache["å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms/ãƒãƒƒãƒ)"] = self._get_metric(metrics, "inference/avg_latency_ms")
        self.results_cache["p95 ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· (ms/ãƒãƒƒãƒ)"] = self._get_metric(metrics, "inference/p95_latency_ms")
        self.results_cache["æ¨è«–æ™‚ Memoey Allocated [MB]"] = self._get_metric(metrics, "inference/avg_peak_mb")

        # ãã®ä»–æƒ…å ±ã‚’å–å¾—
        self.results_cache["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"] = "å®Œäº†"
        if isinstance(trainer.logger, WandbLogger) and trainer.logger.experiment:
            self.results_cache["wandbãƒªãƒ³ã‚¯"] = trainer.logger.experiment.url
        for cb in trainer.callbacks:
            if isinstance(cb, ModelCheckpoint):
                # test_onlyæ™‚ã¯best_model_pathãŒãªã„ã®ã§ã€ãƒ­ãƒ¼ãƒ‰ã—ãŸckptãƒ‘ã‚¹ã‚’ä½¿ã†
                ckpt_path = trainer.ckpt_path or "N/A"
                self.results_cache["ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹"] = cb.best_model_path or ckpt_path
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™
        os.makedirs(os.path.dirname(self.output_file), exist_ok=True)
        file_exists = os.path.isfile(self.output_file)
        with open(self.output_file, "a", newline="", encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=self.headers)
            if not file_exists:
                writer.writeheader()
            
            row_data = {h: self.results_cache.get(h, "") for h in self.headers}
            writer.writerow(row_data)
        
        self.has_written_this_run = True # æ›¸ãè¾¼ã¿å®Œäº†ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        self.results_cache = {} # æ¬¡ã®å®Ÿé¨“ã®ãŸã‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
        print(f"\n[bold magenta]ğŸ“Š å…¨ã¦ã®å®Ÿé¨“çµæœã‚’ {self.output_file} ã«è¨˜éŒ²ã—ã¾ã—ãŸã€‚[/bold magenta]")