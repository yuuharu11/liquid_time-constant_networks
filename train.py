#!/usr/bin/env python3
"""
æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    python train.py                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ
    python train.py dataset=cifar      # ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨
    python train.py model=resnet       # ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
"""

import os
import warnings
import time
from pathlib import Path

import hydra
import pytorch_lightning as pl
import torch
from omegaconf import DictConfig, OmegaConf
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import WandbLogger
from rich import print

# ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚·ã‚¹ãƒ†ãƒ ã¨ utilities
import src.utils as utils
from src.utils import registry

# è­¦å‘Šã‚’æŠ‘åˆ¶ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
warnings.filterwarnings("ignore", category=UserWarning)

# TensorFloat32ã‚’æœ‰åŠ¹åŒ–ï¼ˆå¤§ããªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é«˜é€ŸåŒ–ï¼‰
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True


def setup_logger(cfg: DictConfig) -> WandbLogger:
    """Weights & Biases ãƒ­ã‚¬ãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    logger = WandbLogger(
        project="sequence_models",
        name=f"experiment-{cfg.model.get('_name_', 'unknown')}",
        tags=[cfg.dataset.get('_name_', 'unknown')],
        offline=True,  # é–‹ç™ºä¸­ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³
    )
    return logger


def setup_callbacks(cfg: DictConfig) -> list:
    """PyTorch Lightning ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªçµŒç”±ï¼‰"""
    callbacks = []
    
    # ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
    checkpoint_config = DictConfig({
        '_target_': 'src.callbacks.model_checkpoint.ModelCheckpoint',
        'monitor': 'val_loss',
        'mode': 'min',
        'save_top_k': 3,
        'filename': '{epoch:02d}-{val_loss:.3f}',
        'auto_insert_metric_name': False,
    })
    checkpoint_callback = utils.instantiate(registry.callbacks, checkpoint_config)
    callbacks.append(checkpoint_callback)
    
    print(f"   âœ… ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ : ModelCheckpoint")
    
    return callbacks


def create_trainer(config, **kwargs):
    """ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®ä½œæˆï¼ˆå…ƒã®ãƒªãƒã‚¸ãƒˆãƒªã‚¹ã‚¿ã‚¤ãƒ«ï¼‰"""
    callbacks = setup_callbacks(config)
    logger = setup_logger(config)
    
    # GPUè¨­å®šã®è‡ªå‹•èª¿æ•´
    devices = config.trainer.get("devices", 1)
    if devices > 1:
        print(f"[yellow]ğŸ“Ÿ ãƒãƒ«ãƒGPUè¨­å®šæ¤œå‡º: {devices} devices[/yellow]")
        
    trainer = pl.Trainer(
        logger=logger,
        callbacks=callbacks,
        **config.trainer,
        **kwargs,
    )
    return trainer


@hydra.main(version_base=None, config_path="config", config_name="config")
def main(cfg: DictConfig) -> None:
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # è¨­å®šã‚’è¡¨ç¤º
    print("=" * 80)
    print("[bold green]ğŸš€ æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹[/bold green]")
    print("=" * 80)
    print("\n[bold blue]ğŸ“‹ è¨­å®š:[/bold blue]")
    print(OmegaConf.to_yaml(cfg))
    
    # ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
    if hasattr(cfg.dataset, 'seed'):
        pl.seed_everything(cfg.dataset.seed, workers=True)
        print(f"[green]ğŸ² ã‚·ãƒ¼ãƒ‰è¨­å®š: {cfg.dataset.seed}[/green]")
    
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs("logs", exist_ok=True)
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    print("\n[bold cyan]ğŸ”§ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–...[/bold cyan]")
    trainer = create_trainer(cfg)
    model = SequenceLightningModule(cfg)
    
    print("\n[bold yellow]âš ï¸  ç¾åœ¨ã®å®Ÿè£…çŠ¶æ³:[/bold yellow]")
    print("  âœ… ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚·ã‚¹ãƒ†ãƒ ")
    print("  âœ… åŸºæœ¬æ§‹é€ ã¨Hydraè¨­å®š") 
    print("  âœ… RNNModelå®Ÿè£…")
    print("  âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿè£…")
    print("  âŒ ã‚¿ã‚¹ã‚¯å®Ÿè£…")
    print("  âŒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å®Ÿè£…")
    
    print("\n[bold cyan]ğŸ”§ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:[/bold cyan]")
    print("  1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿè£…")
    print("  2. ã‚¿ã‚¹ã‚¯ï¼ˆæå¤±ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰å®Ÿè£…")
    print("  3. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å®Ÿè£…")
    print("  4. å®Œå…¨ãªè¨“ç·´ãƒ«ãƒ¼ãƒ—")
    
    # è¨­å®šç¢ºèªã¨ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    print(f"\n[green]âœ… è¨­å®šç¢ºèªã¨ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†ï¼[/green]")
    
    # TODO: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿè£…å¾Œã«æœ‰åŠ¹åŒ–
    """
    # è¨“ç·´å®Ÿè¡Œ
    trainer.fit(model)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if cfg.train.test:
        trainer.test(model)
    
    print("âœ… è¨“ç·´å®Œäº†!")
    """


if __name__ == "__main__":
    main()
